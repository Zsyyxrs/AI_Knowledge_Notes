# 一、简介
RAG（Retrieval Augmented Generation）顾名思义，通过**检索**的方法来增强**生成模型**的能力。
搭建过程：
1. 文档加载，并按一定条件切分成文本块
2. 通过embedding模型转换成向量
3. 在向量数据库里根据向量相似度检索得到最高的几组答案
4. 通过query和answer构建prompt给大模型最终得到回复

![](https://cdn.jsdelivr.net/gh/Zsyyxrs/picgo-images/img/rag.png)

离线步骤：
1. 文档加载
2. 文档拆分
3. 向量化
4. 灌入向量数据库
## 在线步骤：
1. 获得用户问题
2. 

# 二、文本切分
pdfminer.six或者pdfplumber解析pdf提取文字等
RAGflow：
普通文本切割：\n 等基于一定规则切分
复杂文本：NSP任务进行微调训练



不同环境下可以放不同的 .env 文件：
.env.dev
.env.prod
load_dotenv(".env.dev")
find_dotenv()在当前路径和父路径找，返回完整路径
不要上传 .env 到 GitHub ，在 .gitignore 中加一行 .env



# 三、文本嵌入和检索
构建向量数据库：选择合适的向量数据库如chromadb、milvus等

| 名称           | 特点                          | 是否开源 | 推荐场景          | 索引支持更新？  | 更新速度  | 索引更新机制                      | 备注          |
| :----------- | :-------------------------- | ---- | :------------ | -------- | ----- | :-------------------------- | :---------- |
| **FAISS**    | Facebook 开源，支持高效 ANN，C++ 实现 | ✅    | 本地部署，研发场景     | ❌（原生不支持） | ❌ 慢   | 需重建索引                       | 适合静态数据      |
| **Milvus**   | 专为大规模向量数据设计，支持多种索引          | ✅    | 大规模医学图像或文本库   | ✅        | ✅ 较快  | 异步增量索引，删除为懒惰删除（lazy delete） | 插入后自动增量索引   |
| **Weaviate** | 自带向量模型，RESTful API 易集成      | ✅    | 快速上线，文档结构化    | ✅        | ✅ 快   | 实时索引，支持 payload 更新          | 非阻塞更新，良好性能  |
| **Qdrant**   | 支持 payload，Python 接口友好      | ✅    | 多模态向量 + 元信息检索 | ✅        | 中等    | HNSW 支持增删改，但需维护结构           | 自动同步更新索引    |
| **Pinecone** | 云服务为主，自动分布式扩展               | ❌    | SaaS 快速构建原型   | ✅        | 商业级优化 | 自有索引机制                      | SaaS，隐藏内部细节 |
| **Chroma**   | 轻量本地，LangChain 默认集成         | ✅    | 小项目 / 测试      | ✅（有限支持）  | 较快    | 简单内存索引或 SQLite 持久化          | 适合个人项目或原型验证 |
选择合适的embedding（文本嵌入）模型：

| **模型**                                | **开发／提供方**    | **典型维度**                 | **语言支持**                | **好处**            | **局限**           | **适合场景**           |
| ------------------------------------- | ------------- | ------------------------ | ----------------------- | ----------------- | ---------------- | ------------------ |
| text‑embedding‑3‑large (OpenAI)       | OpenAI 商用 API | ~ **3072 维**（据 2025 年报道） | 多语言，英语优先                | 高语义准确性；稳定 API；易集成 | 成本高；黑箱；不能自主部署    | 企业级 RAG／生产系统／多语言检索 |
| E5‑Large‑V2／E5 系列（open-source）        | Google / 开源社区 | 多尺寸（如 384／768／1024 维）    | 多语言支持强（含英文、少量跨语）        | 开源可本地部署；成本低；表现佳   | 可能需要 GPU／自部署运维成本 | 自主部署／中型企业／跨语言检索    |
| GTE‑Large 系列（General Text Embeddings） | 开源研究          | ~ 1024 维（Large 版本）       | 多语言                     | 参数相对适中；可细分版本；适合微调 | 社区／工具链可能不如大厂成熟   | 自定义领域检索／中小团队部署     |
| jina‑embeddings‑v3                    | Jina AI（开源）   | 默认 ~ 1024 维（支持降维）        | 多语言／长上下文（如 8192 tokens） | 支持长文本；可调整维度；开源灵活  | 较新，生态较少历史积累      | 长文档检索／多语言／本地化部署    |
| Cohere Embed v3                       | Cohere 商用 API | 支持大上下文（如 8 k tokens）     | 多语言                     | 专注长文档检索；API 方便使用  | 商用成本；开发依赖第三方     | 文档检索／知识库系统／企业服务    |




嵌入模型怎么拆分、训练的 
找项目相关的语料库用LLM进行评估

大多数开源的需要微调

向量嵌入：向量、原文、id的形式写入，列表形式全文档写入
向量检索：向量、top_n，也是列表形式

文本向量
1. 将文本转成一组*N*维浮点数，即**文本向量**又叫 Embeddings
2. 向量之间可以计算距离，距离远近对应**语义相似度**大小

文本向量训练
1. 构建相关（正例）与不相关（负例）的句子对样本
2. 训练双塔式模型，让正例间的距离小，负例间的距离大
[比较语句相似度的SBERT](https://www.sbert.net/)
![](https://cdn.jsdelivr.net/gh/Zsyyxrs/picgo-images/img/sbert.png)
检索后重排序




测试图片
![image.png](https://cdn.jsdelivr.net/gh/Zsyyxrs/picgo-images/img/20251027225616935.png)

向量相似度衡量指标
![](https://cdn.jsdelivr.net/gh/Zsyyxrs/picgo-images/img/sim.png)


向量数据库chroma :不指定embedding模型时用默认的 