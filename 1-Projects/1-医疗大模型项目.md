# 一. 项目概述

## 1.1 **项目背景**
- 家长对婴儿安全、睡眠质量监控的需求    
- 传统摄像头/音频监控的不足
- 目标：通过多模态智能系统实时识别婴儿状态并进行安抚与提醒
## 1.2 **项目目标**
- 自动识别婴儿姿态与行为（趴睡、侧睡、坐起、站立、靠近床沿等）
- 识别婴儿情绪状态（哭闹、高兴、安静）
- 实现异常报警与智能安抚（播放父母声音等）
## 1.3 **系统总体架构**
- 模块划分：感知模块、记忆存储模块、行为执行模块、知识库
- 系统数据流图（可用示意图）
# 二.  硬件系统设计
## 2.1 **主控板选择**
- 选用：CanMV K230
- 选择理由：带NPU支持AI推理、功耗低、适合边缘部署
## 2.2 **传感器模块**
- 摄像头：分辨率、帧率、接口说明
- 麦克风：采样率、噪声处理
- 温湿度传感器选型（如SHT31、DHT11等）及连接方式
- 其他可能扩展传感器（CO₂、动作检测）
## 2.3 **系统连接与供电设计**
- 模块通信方式（I²C、SPI、UART等）
- 电源管理与安全考虑
# 三. 软件与模型设计
## 3.1 **整体软件架构**
- 系统分层（数据采集 → 推理 → 通知 → 控制）
- 模块间通信机制（消息队列、共享内存或RPC）
## 3.2 **感知-视觉识别模块**
- 模型基座：Qwen2.5-VL-7B-Instruct
- 微调方式：LoRA
- 数据类型：视频帧 + 图像
- 分类标签：高兴、哭闹、熟睡、侧卧、剧烈翻身、趴睡、靠近床沿、站立、坐起
- 微调流程与参数设置
- 推理优化（量化、ONNX部署等）
## 3.3 **感知-音频分析模块**
- 特征提取（MFCC、Spectrogram）
- 模型结构（CNN / CRNN / Whisper 小模型等）
- 哭声检测与环境噪声分离
## 3.4 **传感器融合**
- 温湿度数据与婴儿状态的关联
- 多模态融合策略（Early fusion / Late fusion）
## 3.5 **行为执行模块**
- 播放父母语音安抚功能设计
- 环境调节、行为干预
- 通知系统（手机APP / 微信推送 / 本地蜂鸣器）
- 数据同步
## 3.6 **记忆存储模块**
- 长期记忆（用户信息）：平均体温范围、夜醒频率、婴幼儿基本信息
- 短期记忆：当前行为流、任务状态、环境上下文
- 自学习机制：反馈循环、修正策略
# 四. 模型训练与实验
## 4.1 **数据收集与标注**
- 视频数据采集规范：在roboflow上寻找对应的数据集，如baby_posture，douyin-downloader下载douyin视频，yt-dlp下载youtube视频
- 标注工具与标签标准：用label工具标注
- 数据清洗与增强策略：水平翻转，光照/对比度变化，部分图片遮挡，降低分辨率 模糊，趴睡/侧卧角度微调、模糊、遮挡，站立/坐起使用仿射变化 水平翻转
## 4.2 **模型训练**
- 训练流程、环境（PyTorch + LoRA）：A100 8卡机
- 超参数设置与损失函数选择：交叉熵损失函数
- 训练日志与评估指标（准确率、F1、ROC等）
## 4.3 **模型评测**
- 模型在不同姿态和光照下的表现
- 实时性测试与推理延迟
- 边缘部署后的性能对比
# 五. 系统集成与测试
## 5.1 **系统集成**
- 模型推理与传感器数据接口
- 整体流程逻辑：检测→判断→通知→响应
## 5.2 **功能测试**
- 姿态识别正确率
- 哭声检测准确率
- 误报与漏报分析
## 5.3 **性能测试**
- 延迟与吞吐率
- CPU/NPU占用情况
- 功耗评估
# 六. 展示与扩展
## 6.1 **实际演示**
- 效果展示视频或截图
- 不同场景下的识别效果（白天/夜晚）
## 6.2 **未来扩展**
- 添加情绪生成式语音反馈（情感TTS）
- 云端同步与远程监控
- 基于家长习惯的个性化安抚策略
# 七. 总结与反思
## 7.1 **项目成果与意义**
- 实现多模态婴儿行为监测系统的可行性
- 为家庭智能看护提供新思路
## 7.2 **问题与改进方向**
- 数据不足或模型鲁棒性问题
- 传感器精度与校准问题
- 系统延迟与能耗优化

| 问题表现                                                                                                                                                                                                            | 原因                                                                                                                                                                                                                                                                                                                                            | 解决方案                                                                                                                                   |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| 出现keyerror'from'的报错                                                                                                                                                                                             | Format 是sharegpt的role和content tag默认值是from value                                                                                                                                                                                                                                                                                               | 在yaml里加上tag指定role content                                                                                                              |
| 出现None                                                                                                                                                                                                          | 2.3.0+cu121 存在问题，会判断并行度的一个参数为None，但是None不能用in来迭代                                                                                                                                                                                                                                                                                              | 升级到2.5及以上 2.5.1+cu121                                                                                                                  |
| 模型可能输出“这是哭闹状态”/“婴儿当前状态为哭泣”/“看起来像在哭” 等，难以解析和评价                                                                                                                                                                   | 提示词对输出要求不规范，Prompt 是自然语言，预测格式不统一                                                                                                                                                                                                                                                                                                              | 固定prompt模板，请从图像中判断婴儿当前状态，严格按如下格式输出：婴儿当前状态为：「{状态名}」。                                                                                    |
| 训练数据使用的 Prompt 和推理时不同                                                                                                                                                                                           | 如果训练时没用 <image>\n请判断图中婴儿的状态。，模型对这个 pattern 不熟悉                                                                                                                                                                                                                                                                                                | 统一训练和推理的格式                                                                                                                             |
| 状态类别过于主观（哭闹、高兴、靠近床沿），模型难以区分                                                                                                                                                                                     | 训练集没强调输出结构，也易混淆                                                                                                                                                                                                                                                                                                                               | 引导多标签区别性，少量hard case单独做一个数据集再微调                                                                                                        |
| 数据集少                                                                                                                                                                                                            | 每个类别至少30-50张图像，类别尽量相近，防止训练偏倚，如果类别少可以用图像增广                                                                                                                                                                                                                                                                                                     | opencv图像增强，从220张图像增强到1000多张，图像亮度调节模拟白天和黑夜，图像自动旋转，                                                                                      |
| 推理时出现图像字段重复输入问题                                                                                                                                                                                                 | `Qwen2TokenizerFast` 只能处理文本<br><br>`Qwen2_5_VLProcessor` 可以处理文本和图像<br><br>你在用 `tokenizer.apply_chat_template()` 处理消息，然后用 `processor()` 处理图像，这导致了参数冲突                                                                                                                                                                                          | 对于多模态模型，应该统一使用 processor 来处理，避免了 tokenizer 和 processor 之间的冲突                                                                           |
| png绘制中文不显示                                                                                                                                                                                                      | 原因没有中文字体                                                                                                                                                                                                                                                                                                                                      | sudo apt-get update sudo apt-get install fonts-noto-cjk fonts-wqy-zenhei fonts-wqy-microhei                                            |
| Qwen2VLImageProcessorFast works only with image inputs and doesn't process videos anymore. This is a deprecated behavior and will be removed in v5.0. Your videos should be forwarded to Qwen2VLVideoProcessor. | Qwen2VLImageProcessorFast 只处理图像（image），不再支持处理视频（video）；如果你还用它来处理视频，是过时（deprecated）用法，在 v5.0 版本中将会被完全移除，transformers版本过高了，用的是4.52.4                                                                                                                                                                                                            | 将transformers回退到4.49.0<br><br>pip install transformers==4.49.0                                                                         |
| 先用图片微调了一个模型（各种类型：哭闹、趴睡、侧睡、靠近床沿），再在这个模型基础上用视频样本（翻身）进行微调，结果将之前判断正确的图片全都误判为新的了（翻身）                                                                                                                                 | 典型的 “灾难性遗忘（Catastrophic Forgetting）”，尤其是在多模态连续微调（continual fine-tuning）中很常见                                                                                                                                                                                                                                                                   | 联合微调                                                                                                                                   |
| 做视频推理时容易OOM                                                                                                                                                                                                     | 原始处理器接受的是视频地址，抽帧处理的图像很多容易爆显存                                                                                                                                                                                                                                                                                                                  | 对验证视频进行降采样处理，改成传入帧列表的形式，大大减小了显存                                                                                                        |
| 对于高兴、笑的样本识别为0                                                                                                                                                                                                   | 训练时笑脸都是只有脸部表情，使得大模型训练时判别高兴高度绑定只有脸部的视频、图片，多了身体就会判断为其他的                                                                                                                                                                                                                                                                                         | 修改关于高兴的训练集，增加面部表情为高兴但是带有身体的视频给大模型学习                                                                                                    |
| 在用qwen2.5作为基座模型进行推理时存在pad_len=0的情况seq_length(289) - attention_mask_seq_len(289)                                                                                                                                 | qwen2_vl.py中attention_mask_seq_len<br><br>1. 序列长度计算错误：seq_length 参数可能没有正确反映实际的序列长度<br>    <br>2. 注意力掩码长度更新时机错误：在解码阶段，attention_mask_seq_len 的更新可能导致长度不匹配                                                                                                                                                                                      | tokenizer_config.json<br><br>LoRA模型在tokenizer_config.json中新增了：<br><br>- "padding_side": "left" - 指定padding方向<br>    <br><br>去掉这个配置就可以了 |
| 模型推理时生成回复不是自己想要的格式                                                                                                                                                                                              | 原因是template没有对system的提示词做修改，保留了最简单的提示词                                                                                                                                                                                                                                                                                                        | chat_template.json<br><br>tokenizer_config.json 修改template中系统提示词                                                                       |
| 视频tokenizer时会显示index错误                                                                                                                                                                                          | 8个进程同时请求内存进行视频解码<br><br>系统需要释放文件缓存来满足内存请求<br><br>在内存释放过程中，某些进程的内存分配请求失败<br><br>导致数据结构不完整，触发`IndexError`                                                                                                                                                                                                                                       | 内存不足，换机器或者减少视频                                                                                                                         |
| 解压很慢                                                                                                                                                                                                            | df -h . 查看当前挂靠目录<br><br>- 你解压的目标目录 /home/user/gptdata/... 在 **NFS 网络存储** 上（202.127.200.30:/mnt/pool/dataset）<br>    <br>- iostat 显示的 nvme0n1 数据只反映本地 NVMe 盘情况，不会统计 NFS 的 I/O， 所以才看到本地磁盘利用率低，但 unzip 却卡在 D 状态。<br>    <br>- NFS 在解压大量小文件时非常慢，因为每个文件创建/写入都需要网络往返一次（尤其是权限、元数据操作）。<br>    <br>- 这种延迟会直接导致 unzip 一直等 I/O（D 状态），即使 CPU 和本地磁盘几乎是空闲的。 | 先解压到本地目录，然后再拷贝到当前目录                                                                                                                    |
| 直接上传base64编码后的信息时，返回信息不对                                                                                                                                                                                        | Unkown message type，this message may be ignored，在服务器处理时会被忽略                                                                                                                                                                                                                                                                                   | 1、视频存储到服务器可以访问的地址，需要事先配置好ngix信息；<br><br>2、然后传入video_url                                                                                |
| 连接不上网络，显示[Errno 113] EHOSTUNREACH                                                                                                                                                                               | 网络路由层面的问题，分配的网关是0.0.0.0<br><br>DHCP协商时间<br><br>1. **首次连接**：<br>    <br>    1. WIFI认证完成 ≠ IP配置完成<br>        <br>    2. DHCP请求/响应需要额外时间<br>        <br>    3. 你可能在DHCP完成前就检查了配置<br>        <br>2. **再次连接**：<br>    <br>    1. 路由器可能记住了设备<br>        <br>    2. DHCP租约可能还在缓存中<br>        <br>    3. 网络栈已经预热                                      | wifi连接完成后，再给时间等待网络配置完成                                                                                                                 |
| 没有返回结果                                                                                                                                                                                                          | 查询大模型会耗费时间，代码执行时没有等待                                                                                                                                                                                                                                                                                                                          | 增加time_out总超时等待，空闲超时等待时间                                                                                                               |
| Mcp Package not found:                                                                                                                                                                                          | MCP 是一个复杂的协议实现，需要很多标准 Python 库，而 MicroPython 是精简版本，不支持这些依赖。                                                                                                                                                                                                                                                                                   | 自己手动实现                                                                                                                                 |