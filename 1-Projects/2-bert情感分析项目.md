# 一. 项目概述

## 1.1 **项目背景**
- 家长对婴儿安全、睡眠质量监控的需求    
- 传统摄像头/音频监控的不足
- 目标：通过多模态智能系统实时识别婴儿状态并进行安抚与提醒
## 1.2 **项目目标**
- 自动识别婴儿姿态与行为（趴睡、侧睡、坐起、站立、靠近床沿等）
- 识别婴儿情绪状态（哭闹、高兴、安静）
- 实现异常报警与智能安抚（播放父母声音等）
## 1.3 **系统总体架构**
- 模块划分：感知模块、记忆存储模块、行为执行模块、知识库
- 系统数据流图（可用示意图）
# 二.  硬件系统设计
## 2.1 **主控板选择**
- 选用：CanMV K230
- 选择理由：带NPU支持AI推理、功耗低、适合边缘部署
## 2.2 **传感器模块**
- 摄像头：分辨率、帧率、接口说明
- 麦克风：采样率、噪声处理
- 温湿度传感器选型（如SHT31、DHT11等）及连接方式
- 其他可能扩展传感器（CO₂、动作检测）
## 2.3 **系统连接与供电设计**
- 模块通信方式（I²C、SPI、UART等）
- 电源管理与安全考虑
# 三. 软件与模型设计
## 3.1 **整体软件架构**
- 系统分层（数据采集 → 推理 → 通知 → 控制）
- 模块间通信机制（消息队列、共享内存或RPC）
## 3.2 **感知-视觉识别模块**
- 模型基座：Qwen2.5-VL-7B-Instruct
- 微调方式：LoRA
- 数据类型：视频帧 + 图像
- 分类标签：高兴、哭闹、熟睡、侧卧、剧烈翻身、趴睡、靠近床沿、站立、坐起
- 微调流程与参数设置
- 推理优化（量化、ONNX部署等）
## 3.3 **感知-音频分析模块**
- 特征提取（MFCC、Spectrogram）
- 模型结构（CNN / CRNN / Whisper 小模型等）
- 哭声检测与环境噪声分离
## 3.4 **传感器融合**
- 温湿度数据与婴儿状态的关联
- 多模态融合策略（Early fusion / Late fusion）
## 3.5 **行为执行模块**
- 播放父母语音安抚功能设计
- 环境调节、行为干预
- 通知系统（手机APP / 微信推送 / 本地蜂鸣器）
- 数据同步
## 3.6 **记忆存储模块**
- 长期记忆（用户信息）：平均体温范围、夜醒频率、婴幼儿基本信息
- 短期记忆：当前行为流、任务状态、环境上下文
- 自学习机制：反馈循环、修正策略
# 四. 模型训练与实验
## 4.1 **数据收集与标注**
- 视频数据采集规范：在roboflow上寻找对应的数据集，如baby_posture，douyin-downloader下载douyin视频，yt-dlp下载youtube视频
- 标注工具与标签标准：用label工具标注
- 数据清洗与增强策略：水平翻转，光照/对比度变化，部分图片遮挡，降低分辨率 模糊，趴睡/侧卧角度微调、模糊、遮挡，站立/坐起使用仿射变化 水平翻转
## 4.2 **模型训练**
- 训练流程、环境（PyTorch + LoRA）：A100 8卡机
- 超参数设置与损失函数选择：交叉熵损失函数
- 训练日志与评估指标（准确率、F1、ROC等）
## 4.3 **模型评测**
- 模型在不同姿态和光照下的表现
- 实时性测试与推理延迟
- 边缘部署后的性能对比
# 五. 系统集成与测试
## 5.1 **系统集成**
- 模型推理与传感器数据接口
- 整体流程逻辑：检测→判断→通知→响应
## 5.2 **功能测试**
- 姿态识别正确率
- 哭声检测准确率
- 误报与漏报分析
## 5.3 **性能测试**
- 延迟与吞吐率
- CPU/NPU占用情况
- 功耗评估
# 六. 展示与扩展
## 6.1 **实际演示**
- 效果展示视频或截图
- 不同场景下的识别效果（白天/夜晚）
## 6.2 **未来扩展**
- 添加情绪生成式语音反馈（情感TTS）
- 云端同步与远程监控
- 基于家长习惯的个性化安抚策略
# 七. 总结与反思
## 7.1 **项目成果与意义**
- 实现多模态婴儿行为监测系统的可行性
- 为家庭智能看护提供新思路
## 7.2 **问题与改进方向**
- 数据不足或模型鲁棒性问题
- 传感器精度与校准问题
- 系统延迟与能耗优化

[bert模型地址](https://github.com/google-research/bert/blob/master/multilingual.md)
2 种语言，12 层，768 隐藏单元，12 个注意力头，110M 参数

训练过程：
- **type_vocab_size:** 2
- **vocab_size:** 21128
- **num_hidden_layers:** 12

huggingface

数据集用hf上的
训练批次等超参数可以再调一下
日志每n个batch记录一次先不开
train时打印配置信息
wandb：默认先不开
k折交叉验证：默认先不开
做数据处理：文本清洗
训练集和验证集：用原始的数据集
test: 1200
val: 1200
train: 9600
训练集数据用了数据增强，数据增强概率0.1
创建加权采样器（用于不平衡数据）：根据每个样本权重 = 1 / 类别频率分配采样权重，使得数量少的更容易被采样到
drop_last ：训练时最后不完整的批次去掉
pin_memory：DataLoader 会在返回 batch 数据前，**将张量拷贝到固定内存（pinned memory）**，以便 **后续更快地传输到 GPU**。数据驻留在物理内存中，不会被交换出，CUDA 可以直接 DMA（直接内存访问）传输到 GPU
- GPU 从固定内存中读取数据时**速度更快**；
-  数据传输（CPU → GPU）可以异步执行，提高并行度。
解冻最后两层encoder
解冻pooler层
用 Xavier 均匀分布（Xavier Uniform）初始化

|**参数类型**|**初始化方法**|**目的**|
|---|---|---|
|权重 (weight)|用 Xavier / Kaiming 初始化|保持梯度稳定|
|偏置 (bias)|用常数（通常是 0）初始化|保持初始对称性、不影响训练稳定性|

优化器：AdamW

| **参数类型**    | **是否衰减** | **原因**    |
| ----------- | -------- | --------- |
| 线性层权重       | ✅        | 正则化以防过拟合  |
| 偏置项         | ❌        | 避免干扰偏移量学习 |
| LayerNorm权重 | ❌        | 保持归一化稳定性  |

warm_up：在训练初期逐步增加学习率，从一个较小的值线性或按规则“升温”到目标学习率，从而让模型训练更稳定、收敛更快。
学习率调度器：采用升温后线性下降的设置，根据设置的WARMUP_RATIO 总步数计算WARMUP步数
采用混合精度训练：torch.amp.GradScaler()可以混合精度训练时自动缩放梯度